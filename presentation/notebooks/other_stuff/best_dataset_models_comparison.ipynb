{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39015fa",
   "metadata": {},
   "source": [
    "# Compare SVM with other models with same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2629fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results():\n",
    "    report_path = \"../../../notebooks/artifacts/punctuation_no_stop_words/test_results.csv\"\n",
    "    svm_path = \"../artifacts/svm/test_results.csv\"\n",
    "    lemmatization_path = \"../artifacts/lemmatization/test_results.csv\"\n",
    "    ngrams_path = \"../artifacts/ngrams/test_results.csv\"\n",
    "    \n",
    "    df_main = pd.read_csv(report_path)\n",
    "    df_svm = pd.read_csv(svm_path)\n",
    "    df_lemmatization = pd.read_csv(lemmatization_path)\n",
    "    df_ngrams = pd.read_csv(ngrams_path)\n",
    "    \n",
    "    # Combine them into one DataFrame\n",
    "    combined_df = pd.concat([df_main, df_svm, df_lemmatization, df_ngrams], ignore_index=True)\n",
    "    \n",
    "    # Ensure all columns are numeric for plotting (except Model)\n",
    "    # This handles any 'stillrunning' strings if they were saved to the CSV\n",
    "    metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "    for metric in metrics:\n",
    "        combined_df[metric] = pd.to_numeric(combined_df[metric], errors='coerce')\n",
    "    \n",
    "    # Drop rows that ended up with NaN after conversion (if any)\n",
    "    return combined_df.dropna(subset=['accuracy'])\n",
    "\n",
    "df = load_all_results()\n",
    "df_melted = df.melt(id_vars='Model', var_name='Metric', value_name='Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a grouped bar chart\n",
    "plot = sns.barplot(data=df_melted, x=\"Model\", y=\"Score\", hue=\"Metric\", palette=\"viridis\")\n",
    "\n",
    "# Formatting\n",
    "plt.title(\"Model Performance Comparison (Including SVM)\", fontsize=15)\n",
    "plt.ylim(0.8, 1.0)  # Adjusting view to see small differences\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "# --- GRAPH 1: Modern Grouped Bar Chart ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_melted, x='Model', y='Score', hue='Metric', palette='viridis')\n",
    "plt.title('Comparison of Model Performance Metrics', fontsize=14)\n",
    "plt.ylim(0.8, 1.0) # Zoom in to see differences\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('grouped_bar_chart.png')\n",
    "\n",
    "# --- GRAPH 2: Radar (Spider) Chart ---\n",
    "def create_radar_chart(df, metrics):\n",
    "    categories = metrics\n",
    "    N = len(categories)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1] # Close the circle\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        values = row[metrics].values.flatten().tolist()\n",
    "        values += values[:1] # Close the circle\n",
    "        ax.plot(angles, values, linewidth=2, label=row['Model'])\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "    \n",
    "    plt.xticks(angles[:-1], categories, size=12)\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0.85, 0.90, 0.95], [\"0.85\", \"0.90\", \"0.95\"], color=\"grey\", size=8)\n",
    "    plt.ylim(0.8, 1.0)\n",
    "    plt.title('Model Performance Profiles (Radar Chart)', size=15, y=1.1)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('radar_chart.png')\n",
    "\n",
    "create_radar_chart(df, metrics)\n",
    "\n",
    "# --- GRAPH 3: Precision-Recall Trade-off (Scatter Plot) ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='recall_macro', y='precision_macro', hue='Model', s=200, style='Model')\n",
    "plt.title('Precision vs. Recall Trade-off', fontsize=14)\n",
    "plt.xlabel('Recall (Macro)')\n",
    "plt.ylabel('Precision (Macro)')\n",
    "\n",
    "# Label each point so you don't just rely on the legend\n",
    "for i in range(df.shape[0]):\n",
    "    plt.text(df.recall_macro[i]+0.001, df.precision_macro[i], df.Model[i], fontsize=9)\n",
    "\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig('precision_recall_scatter.png')\n",
    "\n",
    "# --- GRAPH 4: Heatmap of Results ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "heatmap_data = df.set_index('Model')\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt='.4f')\n",
    "plt.title('Heatmap of Model Metrics', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('performance_heatmap.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
