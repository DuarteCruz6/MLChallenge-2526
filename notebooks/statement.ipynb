{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b448df",
   "metadata": {},
   "source": [
    "# 1 - Model Training and Evaluation\n",
    "\n",
    "## a) Extract TF-IDF features from the text with a maximum number of features (terms) set to 5000. Make sure to add smoothing for out-of-vocabulary (OOV) words (idf smoothing). Define the minimum and maximum number of documents a term must appear in as min_df=10, and the maximum proportion of documents a term can appear in as max_df=0.9.\n",
    "\n",
    "## b) Train the following models using 5-fold cross-validation, tune key hyperparameters systematically (e.g., regularization strength λ, tree depth), and document your hyperparameter search process.\n",
    "### • Decision Tree\n",
    "### • Gaussian Naive Bayes\n",
    "### • Logistic Regression with L2 regularization\n",
    "### • Logistic Regression with L1 regularization\n",
    "### • Multi-Layer Perceptron (MLP) - You are free to choose your architecture but up to 2 hidden layers.\n",
    "\n",
    "## c)  Create a comparison table with test metrics: Accuracy, Precision, Recall, and F1-score. For the best classifier, draw its ROC curve and compute AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b8f71a",
   "metadata": {},
   "source": [
    "# 2 - Model Interpretation\n",
    "\n",
    "## a) For your best Logistic Regression model, extract and visualize the weights in a bar plot:\n",
    "### • Top 10 words most indicative of fake news\n",
    "### • Top 10 words most indicative of real news\n",
    "\n",
    "## b) Compare L1 vs L2 regularized models: How many features have non-zero weights in each? What does this tell you about feature selection? When would you prefer L1 vs L2 regularization for text classification?\n",
    "\n",
    "## c) For your best Logistic Regression model, select samples in the validation set with ID 2921, 2437, 5557, 1697, and extract explanations with LIME (Ribeiro et al., 2016; Lundberg and Lee, 2017). For a practical reference, check [this](https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html)\n",
    "\n",
    "## d) For your MLP, select samples in the validation set with ID 2921, 2437, 5557, 1697, and extract explanations with LIME and permutation importance. For permutation importance, select 1K random samples. Visualize the results and discuss their differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec8f7c",
   "metadata": {},
   "source": [
    "# 3 - Clustering\n",
    "\n",
    "## a) Apply K-Means with K=5 on your training set.\n",
    "\n",
    "## b) Inspect 3 documents closest to each centroid, and afterwards, assign semantic labels to each cluster (e.g., “political fake news”, “health misinformation”).\n",
    "\n",
    "## c) Visualize clusters in 2D using PCA. Create two plots: one colored by cluster assignment, one by true label."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
